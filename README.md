# About the Author
Allan Mutisya develops machine learning and deep learning solutions for structured, image, and text data, analytics and insights, innovation lab in Kenya. He has acquired a lot of experience in both analytics and data science. He received his Data science excellence certificate from Moringa School. He is an artificial intelligence enthusiast. When not working, he likes to read about next-gen technologies and innovative methodologies.


# STATISTICS-FOR-MACHINE-DEEP-LEARNING
This repository contains statistics for machine learning. I have created this repository in order to help upcoming data scientists learn the statistics behind machine learning

Complex statistics in machine learning worry a lot of developers. Knowing statistics helps you build strong machine learning models that are optimized for a given problem statement. I believe that any machine learning practitioner should be proficient in statistics as well as in mathematics, so that they can speculate and solve any machine learning problem in an efficient manner. In this Notebook, we will cover the fundamentals of statistics and machine learning, giving you a holistic view of the application of machine learning techniques for relevant problems. We will discuss the application of frequently used algorithms on various domain problems, using both Python programming. We will use libraries such as scikit-learn, xgboost, and so on. We will also go over the fundamentals of deep learning with the help of Keras software. Furthermore, we will have an overview of reinforcement learning with pure Python programming language.

# Journey from Statistics to Machine Learning
In recent times, machine learning (ML) and data science have gained popularity like never before. This field is expected to grow exponentially in the coming years. First of all, what is machine learning? And why does someone need to take pains to understand the principles? Well, we have the answers for you. One simple example could be book recommendations in e-commerce websites when someone went to search for a particular book or any other product recommendations which were bought together to provide an idea to users which they might like. Sounds magic, right? In fact, utilizing machine learning, can achieve much more than this.

Machine learning is a branch of study in which a model can learn automatically from the experiences based on data without exclusively being modeled like in statistical models. Over a period and with more data, model predictions will become better.

In this chapter, we will cover the following:

1. Statistical terminology for model building and validation
Statistics are mainly classified into two subbranches: 
a) Descriptive statistics: These are used to summarize data, such as the mean, standard deviation for continuous data types (such as age), whereas frequency and percentage are useful for categorical data (such as gender).

b) Inferential statistics: Many times, a collection of the entire data (also known as population in statistical methodology) is impossible, hence a subset of the data points is collected, also called a sample, and conclusions about the entire population will be drawn, which is known as inferential statistics. Inferences are drawn using hypothesis testing, the estimation of numerical characteristics, the correlation of relationships within data, and so on.

2. Machine learning terminology for model building and validation
Machine learning is the branch of computer science that utilizes past experience to learn from and use its knowledge to make future decisions. Machine learning is at the intersection of computer science, engineering, and statistics. The goal of machine learning is to generalize a detectable pattern or to create an unknown rule from given examples.

3. Machine learning model overview
Machine learning is broadly classified into three categories but nonetheless, based on the situation, these categories can be combined to achieve the desired results for particular applications: a) Supervised learning: This is teaching machines to learn the relationship between other variables and a target variable, similar to the way in which a teacher provides feedback to students on their performance. The major segments within supervised learning are as follows: Classification problem Regression problem b) Unsupervised learning: In unsupervised learning, algorithms learn by themselves without any supervision or without any target variable provided. It is a question of finding hidden patterns and relations in the given data. The categories in unsupervised learning are as follows: Dimensionality reduction Clustering C) Reinforcement learning: This allows the machine or agent to learn its behavior based on feedback from the environment. In reinforcement learning, the agent takes a series of decisive actions without supervision and, in the end, a reward will be given, either +1 or -1. Based on the final payoff/reward, the agent reevaluates its paths. Reinforcement learning problems are closer to the artificial intelligence methodology rather than frequently used machine learning algorithms.


# Steps in machine learning model development and deployment
The development and deployment of machine learning models involves a series of steps that are almost similar to the statistical modeling process, in order to develop, validate, and implement machine learning models. The steps are as follows:

Collection of data: Data for machine learning is collected directly from structured source data, web scrapping, API, chat interaction, and so on, as machine learning can work on both structured and unstructured data (voice, image, and text).
Data preparation and missing/outlier treatment: Data is to be formatted as per the chosen machine learning algorithm; also, missing value treatment needs to be performed by replacing missing and outlier values with the mean/median, and so on.
Data analysis and feature engineering: Data needs to be analyzed in order to find any hidden patterns and relations between variables, and so on. Correct feature engineering with appropriate business knowledge will solve 70 percent of the problems. Also, in practice, 70 percent of the data scientist's time is spent on feature engineering tasks.
Train algorithm on training and validation data: Post feature engineering, data will be divided into three chunks (train, validation, and test data) rather than two (train and test) in statistical modeling. Machine learning are applied on training data and the hyperparameters of the model are tuned based on validation data to avoid overfitting.
Test the algorithm on test data: Once the model has shown a good enough performance on train and validation data, its performance will be checked against unseen test data. If the performance is still good enough, we can proceed to the next and final step.
Deploy the algorithm: Trained machine learning algorithms will be deployed on live streaming data to classify the outcomes. One examplecould be recommender systems implemented by e-commerce websites







